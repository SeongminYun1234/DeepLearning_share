{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88bcdb279828232e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T07:20:49.903094Z",
     "start_time": "2025-09-21T07:20:49.898983Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cc7a4640a00977",
   "metadata": {},
   "source": [
    "a_tensor_initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20fa7304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "cpu\n",
      "False\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.Tensor([1, 2, 3], device='cpu')\n",
    "print(t1.dtype)\n",
    "print(t1.device)\n",
    "print(t1.requires_grad)\n",
    "print(t1.size())\n",
    "print(t1.shape)\n",
    "\n",
    "t1_cpu = t1.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6be82d6206632f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "cpu\n",
      "False\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "t2 = torch.tensor([1, 2, 3], device='cpu')\n",
    "print(t2.dtype)\n",
    "print(t2.device)\n",
    "print(t2.requires_grad)\n",
    "print(t2.size())\n",
    "print(t2.shape)\n",
    "\n",
    "t2_cpu = t2.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e097c19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([]) 0\n",
      "torch.Size([1]) 1\n",
      "torch.Size([5]) 1\n",
      "torch.Size([5, 1]) 2\n",
      "torch.Size([3, 2]) 2\n",
      "torch.Size([3, 2, 1]) 3\n",
      "torch.Size([3, 1, 2, 1]) 4\n",
      "torch.Size([3, 1, 2, 3]) 4\n",
      "torch.Size([4, 5]) 2\n",
      "torch.Size([4, 1, 5]) 3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 3 at dim 3 (got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     56\u001b[39m a10 = torch.tensor([\n\u001b[32m     57\u001b[39m     [[\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m]],\n\u001b[32m     58\u001b[39m     [[\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m]],\n\u001b[32m     59\u001b[39m     [[\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m]],\n\u001b[32m     60\u001b[39m     [[\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m]]\n\u001b[32m     61\u001b[39m ])\n\u001b[32m     62\u001b[39m \u001b[38;5;28mprint\u001b[39m(a10.shape, a10.ndim)\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m a11 = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;28mprint\u001b[39m(a11.shape, a11.ndim)\n",
      "\u001b[31mValueError\u001b[39m: expected sequence of length 3 at dim 3 (got 2)"
     ]
    }
   ],
   "source": [
    "a1 = torch.tensor(1)\n",
    "print(a1.shape, a1.ndim)\n",
    "\n",
    "a2 = torch.tensor([1])\n",
    "print(a2.shape, a2.ndim)\n",
    "\n",
    "a3 = torch.tensor([1, 2, 3, 4, 5])\n",
    "print(a3.shape, a3.ndim)\n",
    "\n",
    "a4 = torch.tensor([[1], [2], [3], [4], [5]])\n",
    "print(a4.shape, a4.ndim)\n",
    "\n",
    "a5 = torch.tensor([\n",
    "    [1, 2],\n",
    "    [3, 4],\n",
    "    [5, 6]\n",
    "])\n",
    "print(a5.shape, a5.ndim)\n",
    "\n",
    "a6 = torch.tensor([\n",
    "    [[1], [2]],\n",
    "    [[3], [4]],\n",
    "    [[5], [5]]\n",
    "])\n",
    "print(a6.shape, a6.ndim)\n",
    "\n",
    "a7 = torch.tensor([\n",
    "    [[[1], [2]]],\n",
    "    [[[3], [4]]],\n",
    "    [[[5], [6]]]\n",
    "])\n",
    "print(a7.shape, a7.ndim)\n",
    "\n",
    "\n",
    "a8 = torch.tensor([\n",
    "    [[[1, 2, 3],[2, 3, 4]]],\n",
    "    [[[3, 1, 1],[4, 4, 5]]],\n",
    "    [[[5, 6, 2],[6, 3, 1]]]\n",
    "])\n",
    "print(a8.shape, a8.ndim)\n",
    "\n",
    "a9 = torch.tensor([\n",
    "    [[[[1],[2],[3]],[[2],[3],[4]]]],\n",
    "    [[[[3],[1],[1]],[[4],[4],[5]]]],\n",
    "    [[[[5],[6],[2]],[[6],[3],[1]]]]\n",
    "])\n",
    "\n",
    "a10 = torch.tensor([\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5]\n",
    "])\n",
    "print(a10.shape, a10.ndim)\n",
    "\n",
    "a10 = torch.tensor([\n",
    "    [[1, 2, 3, 4, 5]],\n",
    "    [[1, 2, 3, 4, 5]],\n",
    "    [[1, 2, 3, 4, 5]],\n",
    "    [[1, 2, 3, 4, 5]]\n",
    "])\n",
    "print(a10.shape, a10.ndim)\n",
    "\n",
    "\n",
    "a11 = torch.tensor([\n",
    "    [[[1, 2, 3], [4, 5]]],\n",
    "    [[[1, 2, 3], [4, 5]]],\n",
    "    [[[1, 2, 3], [4, 5]]],\n",
    "    [[[1, 2, 3], [4, 5]]],\n",
    "])\n",
    "print(a11.shape, a11.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32517e6d600586e",
   "metadata": {},
   "source": [
    "b_tensor_initialization_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "618fd6925d5db547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9baeb14618a351c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([1, 2, 3])\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "l1 = [1, 2, 3]\n",
    "t1 = torch.Tensor(l1) #torch.Tensor : torch.float32\n",
    "\n",
    "l2 = [1, 2, 3]\n",
    "t2 = torch.tensor(l2) #torch.tensor : torch.int64\n",
    "\n",
    "l3 = [1, 2, 3]\n",
    "t3 = torch.as_tensor(l3)\n",
    "# torch.as_tensor\n",
    "# numpy 배열에서는 가능한 원본 메모리 공유\n",
    "# 파이썬 리스트는 객체 포인터 참조이기 때문에 원본 메모리 공유 불가(복사본 생성)\n",
    "\n",
    "l1[0] = 100\n",
    "l2[0] = 100\n",
    "l3[0] = 100\n",
    "\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f11ba2c081213c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([1, 2, 3])\n",
      "tensor([100,   2,   3])\n"
     ]
    }
   ],
   "source": [
    "l4 = np.array([1, 2, 3])\n",
    "t4 = torch.Tensor(l4)\n",
    "\n",
    "l5 = np.array([1, 2, 3])\n",
    "t5 = torch.tensor(l5)\n",
    "\n",
    "l6 = np.array([1, 2, 3])\n",
    "t6 = torch.as_tensor(l6)\n",
    "\n",
    "l4[0] = 100\n",
    "l5[0] = 100\n",
    "l6[0] = 100\n",
    "\n",
    "print(t4)\n",
    "print(t5)\n",
    "print(t6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74a083ea858b369",
   "metadata": {},
   "source": [
    "c_tensor_initialization_constant_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4364aa9a73582dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "tensor([9.2194e-41, 0.0000e+00, 0.0000e+00, 0.0000e+00])\n",
      "tensor([2., 0., 0., 0.])\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.ones(size=(5,)) # or torch.ones(5) torch.ones 같은 함수는 튜플을 사용하지 않아도 내부에서 튜플로 변환 size=(5,) → 튜플형태\n",
    "t1_like = torch.ones_like(input=t1) #input과 크기가 같은 텐서를 만들고 1로 채움\n",
    "print(t1)\n",
    "print(t1_like)\n",
    "\n",
    "t2 = torch.zeros(size=(6,))\n",
    "t2_like = torch.zeros_like(input=t2)\n",
    "print(t2)\n",
    "print(t2_like)\n",
    "\n",
    "#input과 크기가 같은 텐서를 만들지만, 메모리만 할당하고 초기화는 하지 않음\n",
    "#안에 들어가는 값이 쓰레기 값(garbage value)일 수 있기 때문에 재초기화 필수!!\n",
    "t3 = torch.empty(size=(4,))\n",
    "t3_like = torch.empty_like(input=t3)\n",
    "print(t3)\n",
    "print(t3_like)\n",
    "\n",
    "t4 = torch.eye(n=3) # torch.eye : 단위 행렬(대각선은 1, 나머지는 0)\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c1ba0d511ad098",
   "metadata": {},
   "source": [
    "d_tensor_initialization_random_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8455448840f49277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[16, 14]])\n",
      "tensor([[0.3413, 0.5217, 0.2111]])\n",
      "tensor([[ 1.0257,  2.2207, -1.8842]])\n",
      "tensor([[11.8888,  9.2489],\n",
      "        [ 9.3426,  9.4615],\n",
      "        [10.2818, 11.0190]])\n",
      "tensor([0.0000, 2.5000, 5.0000])\n",
      "tensor([0, 1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "#torch.randint\n",
    "# 주어진 [low,high) 범위 내에서 정수(int)난수 균일 분포 생성\n",
    "t1 = torch.randint(low=10, high=20, size=(1, 2))\n",
    "print(t1)\n",
    "\n",
    "#torch.rand\n",
    "#[0, 1)사이 난수 균일 분포 생성\n",
    "t2 = torch.rand(size=(1, 3))\n",
    "print(t2)\n",
    "\n",
    "#torch.randn\n",
    "#정규분포 N(0,1)(평균 0, 포준편차 1)에서 난수 생성, 신경망 가중치 초기화할 때 사용\n",
    "t3 = torch.randn(size=(1, 3))\n",
    "print(t3)\n",
    "\n",
    "#torch.normal\n",
    "#임의의 평균(mean), 표준편차(std)를 갖는 정규분포에서 샘플링\n",
    "t4 = torch.normal(mean=10.0, std=1.0, size=(3, 2))\n",
    "print(t4)\n",
    "\n",
    "#torch.linspace\n",
    "#start~end까지 등분된 구간으로 나눈 실수 값을 생성\n",
    "#steps 개수만큼 값을 만듬(end 포함)\n",
    "#연속 구간을 균등 분할할때 유용\n",
    "t5 = torch.linspace(start=0.0, end=5.0, steps=3)\n",
    "print(t5)\n",
    "\n",
    "#torch.arange(start, end, step)\n",
    "#start~end까지 step간격으로 값 생성\n",
    "t6 = torch.arange(5)\n",
    "print(t6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7afd87d6a3cb6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n",
      "tensor([[0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938]])\n",
      "\n",
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n",
      "tensor([[0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938]])\n"
     ]
    }
   ],
   "source": [
    "#torch.manual_seed()\n",
    "#특정 시드(정수값)을 지정하여서 해당시드로는 난수 발생을 고정하여 동일한 결과를 공유할 수 있게 하는 함수\n",
    "#실험 반복 시 결과 공유에 쓰임\n",
    "#난수 생성의 시작점을 안정적으로 유지함\n",
    "torch.manual_seed(1729)\n",
    "random1 = torch.rand(2, 3)\n",
    "print(random1)\n",
    "\n",
    "random2 = torch.rand(2, 3)\n",
    "print(random2)\n",
    "\n",
    "print()\n",
    "\n",
    "torch.manual_seed(1729)\n",
    "random3 = torch.rand(2, 3)\n",
    "print(random3)\n",
    "\n",
    "random4 = torch.rand(2, 3)\n",
    "print(random4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966327f398794391",
   "metadata": {},
   "source": [
    "e_tensor_type_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ee7326713d65f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int16)\n",
      "tensor([[18.0429,  7.2532, 19.6519],\n",
      "        [10.8626,  2.1505, 19.6913]], dtype=torch.float64)\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int32)\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]], dtype=torch.float64)\n",
      "tensor([1, 2], dtype=torch.int16)\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]], dtype=torch.float64)\n",
      "tensor([[1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1]], dtype=torch.int16)\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]], dtype=torch.float64)\n",
      "tensor([[0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0]], dtype=torch.int16)\n",
      "torch.float64\n",
      "torch.int16\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "a=torch.ones((2, 3))\n",
    "print(a.dtype)\n",
    "\n",
    "b=torch.ones((2, 3), dtype=torch.int16)\n",
    "print(b)\n",
    "\n",
    "c = torch.rand((2, 3), dtype=torch.float64) * 20\n",
    "print(c)\n",
    "\n",
    "d = b.to(torch.int32)\n",
    "print(d)\n",
    "\n",
    "#torch.double 사용 시 float64로 자료형태를 띔\n",
    "#torch.short 사용 시 int16로 자료형태를 띔\n",
    "double_d = torch.ones(10, 2, dtype=torch.double)\n",
    "short_e = torch.tensor([1, 2], dtype=torch.short)\n",
    "\n",
    "print(double_d)\n",
    "print(short_e)\n",
    "\n",
    "double_d = torch.zeros(10, 2).double()\n",
    "short_e = torch.ones(10, 2).short()\n",
    "print(double_d)\n",
    "print(short_e)\n",
    "\n",
    "double_d = torch.zeros(10, 2).to(torch.double)\n",
    "short_e = torch.zeros(10, 2).to(dtype=torch.short)\n",
    "print(double_d)\n",
    "print(short_e)\n",
    "\n",
    "double_d = torch.zeros(10, 2).type(torch.double)\n",
    "short_e = torch.zeros(10, 2).type(dtype=torch.short)\n",
    "\n",
    "print(double_d.dtype)\n",
    "print(short_e.dtype)\n",
    "\n",
    "# 서로 다른 유형일때는 int보다 float가 우선 시\n",
    "double_f = torch.rand(5, dtype=torch.double)\n",
    "short_g = double_f.to(torch.short)\n",
    "print((double_f * short_g).dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b88842cc1771211",
   "metadata": {},
   "source": [
    "f_tensor_operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52e8a74e1bb4e75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "#torch.add\n",
    "#텐서 값 더하기\n",
    "t1 = torch.ones(size=(2, 3))\n",
    "t2 = torch.ones(size=(2, 3))\n",
    "t3 = torch.add(t1, t2)\n",
    "t4 = t1 + t2\n",
    "print(t3)\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e891a692b048d153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "#torch.sub\n",
    "#텐서 값 뺄셈\n",
    "t5 = torch.sub(t1, t2)\n",
    "t6 = t1 - t2\n",
    "print(t5)\n",
    "print(t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66f1fbde56193b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#torch.mul\n",
    "#텐서 값 곱하기\n",
    "t7 = torch.mul(t1, t2)\n",
    "t8 = t1 *t2\n",
    "print(t7)\n",
    "print(t8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ee389933fe756cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#torch.div\n",
    "#텐서 값 나누기\n",
    "t9 = torch.div(t1, t2)\n",
    "t10 = t1 / t2\n",
    "print(t9)\n",
    "print(t10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ab1d754b26efcd",
   "metadata": {},
   "source": [
    "g_tensor_operations_mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4851a0fd65b03ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7) torch.Size([])\n",
      "tensor([[1.6750, 2.2840],\n",
      "        [0.0956, 1.0294]]) torch.Size([2, 2])\n",
      "torch.Size([10, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "#torch.dot()\n",
    "#\"스칼라 곱\"을 수행\n",
    "t1 = torch.dot(\n",
    "    torch.tensor([2, 3]), torch.tensor([2, 1])\n",
    ")\n",
    "print(t1, t1.size()) # 2*2 + 3*1 = 7\n",
    "\n",
    "#torch.mm()\n",
    "#2차원의 계산 \"행렬 곱\"을 수행\n",
    "t2 = torch.randn(2, 3) #torch.randn(n, p)\n",
    "t3 = torch.randn(3, 2) #torch.randn(p, m)\n",
    "t4 = torch.mm(t2, t3) #torch.randn(n, m)\n",
    "print(t4, t4.size())\n",
    "\n",
    "#torch.bmm\n",
    "# 3차원 텐서의 \"배치 수행 곱\"\n",
    "# 배치 크기는 동일해야함!!\n",
    "t5 = torch.randn(10, 3, 4) #torch.randn(batch_size, n, p)\n",
    "t6 = torch.randn(10, 4, 5) #torch.randn(batch_size, p, m)\n",
    "t7 = torch.bmm(t5, t6) #torch.randn(batch_size, n, m)\n",
    "print(t7.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2775a68325e1e8",
   "metadata": {},
   "source": [
    "h_tensor_operations_matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "614021a5861c740c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T08:26:28.251926Z",
     "start_time": "2025-09-21T08:26:28.222930Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "torch.Size([3])\n",
      "torch.Size([10, 3])\n",
      "torch.Size([10, 3, 5])\n",
      "torch.Size([10, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "# vector x vector : dot product\n",
    "# 두 텐서가 모두 1차원인 경우 \"내적\"으로 계산\n",
    "t1 = torch.randn(3)\n",
    "t2 = torch.randn(3)\n",
    "print(torch.matmul(t1, t2).size())\n",
    "\n",
    "# 행렬 x 벡터 : 브로드캐스팅-내적\n",
    "t3 = torch.randn(3, 4)\n",
    "t4 = torch.randn(4)\n",
    "print(torch.matmul(t3, t4).size())\n",
    "\n",
    "# 배치 행렬 x 벡터 : 브로드캐스팅-내적\n",
    "# 1차원 텐서(벡터)를 열 벡터로 취급 [4, 1] 이후 [3, 4] x [4, 1] -> [3, 1] -> [3]\n",
    "t5 = torch.randn(10, 3, 4)\n",
    "t6 = torch.randn(4)\n",
    "print(torch.matmul(t5, t6).size())\n",
    "\n",
    "# 배치 행렬 x 배치 행렬 : bmm\n",
    "t7 = torch.randn(10, 3, 4)\n",
    "t8 = torch.randn(10, 4, 5)\n",
    "print(torch.matmul(t7, t8).size())\n",
    "\n",
    "# 배치 행렬 x 행렬 : bmm\n",
    "# 한쪽 텐서만 배치 차원이 있다면 다른 텐서는 모든 배치에 대해 브로드캐스팅됨.\n",
    "# >> 배치 차원을 가진 텐서의 모든 배치에 대해 동일하게 복사되어 연산에 참여하는 것\n",
    "t9 = torch.randn(10, 3, 4)\n",
    "t10 = torch.randn(4, 5)\n",
    "print(torch.matmul(t9, t10).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b842fa6af6b95b4",
   "metadata": {},
   "source": [
    "i_tensor_broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "109aca8a7b891796",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T08:53:11.472150Z",
     "start_time": "2025-09-21T08:53:11.427877Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 4., 6.])\n"
     ]
    }
   ],
   "source": [
    "# 1차원 텐서 x 파이썬 실수 : 브로드캐스팅 (파이썬 실수 → 0차원 텐서-스칼라)\n",
    "t1 = torch.tensor([1.0, 2.0, 3.0])\n",
    "t2 = 2.0\n",
    "print(t1 * t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6832425783dddfe3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T08:57:18.459908Z",
     "start_time": "2025-09-21T08:57:18.433726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4, -4],\n",
      "        [-2, -1],\n",
      "        [ 6,  5]])\n"
     ]
    }
   ],
   "source": [
    "# 브로드캐스팅-가상확장\n",
    "# t4의 모양이 t3와 호환되도록 (1, 2)모양으로 간주\n",
    "t3 = torch.tensor([[0, 1], [2, 4], [10, 10]])\n",
    "t4 = torch.tensor([4, 5])\n",
    "print(t3 - t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a79027854d52e8a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T13:41:04.706800Z",
     "start_time": "2025-09-21T13:41:04.690769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[-1.,  0.],\n",
      "        [ 1.,  2.]])\n",
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n",
      "tensor([[0.5000, 1.0000],\n",
      "        [1.5000, 2.0000]])\n"
     ]
    }
   ],
   "source": [
    "t5 = torch.tensor([[1., 2.],[3., 4.]])\n",
    "print(t5 + 2.0) #t5.add(2.0)\n",
    "print(t5 - 2.0) #t5.sub(2.0)\n",
    "print(t5 * 2.0) #t5.mul(2.0)\n",
    "print(t5 / 2.0) #t5.div(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9b0669df56bb7a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T09:23:29.179896Z",
     "start_time": "2025-09-21T09:23:29.172553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# 텐서에 함수 적용\n",
    "def normalize(x):\n",
    "    return x / 255\n",
    "\n",
    "t6 = torch.randn(3, 28, 28)\n",
    "print(normalize(t6).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "275c10c44193e7cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T09:59:19.872029Z",
     "start_time": "2025-09-21T09:59:19.860234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 3],\n",
      "        [3, 4]])\n",
      "tensor([[6, 7],\n",
      "        [2, 5]])\n",
      "tensor([[8, 6],\n",
      "        [5, 3]])\n",
      "tensor([[ 8,  9],\n",
      "        [ 7, 10]])\n"
     ]
    }
   ],
   "source": [
    "t7 = torch.tensor([[1, 2],[0, 3]])\n",
    "t8 = torch.tensor([[3, 1]])\n",
    "t9 = torch.tensor([[5], [2]])\n",
    "t10 = torch.tensor([7])\n",
    "print(t7 + t8)\n",
    "print(t7 + t9)\n",
    "print(t8 + t9)\n",
    "print(t7 + t10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7da12d2bdafd70c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T13:53:10.342346Z",
     "start_time": "2025-09-21T13:53:10.319293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 2])\n",
      "torch.Size([4, 3, 2])\n",
      "torch.Size([4, 3, 2])\n",
      "<built-in method size of Tensor object at 0x0000020A1FA3D950>\n"
     ]
    }
   ],
   "source": [
    "# 브로드캐스팅 규칙\n",
    "# 두 텐서의 모양을 뒤에서부터 비교\n",
    "# 최종 결과 모양\n",
    "# 연산이 간으한 경우, 결과 텐서의 모양은 각 차원에서 입력 텐서의 가장 큰 크기를 따름\n",
    "\n",
    "# 첫 번째 차원이 t11은 4이지만, torch.rand(3, 2)는 없음\n",
    "# 이 경우 torch.rand(3, 2)의 모양을 (1, 3, 2)로 가상 확장\n",
    "t11 = torch.ones(4, 3, 2)\n",
    "t12 = t11 * torch.rand(3, 2)\n",
    "print(t12.shape)\n",
    "\n",
    "t13 = torch.ones(4, 3, 2)\n",
    "t14 = t12 * torch.rand(3, 1)\n",
    "print(t14.shape)\n",
    "\n",
    "t15 = torch.ones(4, 3, 2)\n",
    "t16 = t15 * torch.rand(1, 2)\n",
    "print(t16.shape)\n",
    "\n",
    "t17 = torch.ones(5, 3, 4, 1)\n",
    "t18 = torch.rand(3, 1, 1)\n",
    "print((t17 + t18).size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "18c8588d47130591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method size of Tensor object at 0x0000020A1FA3F160>\n",
      "<built-in method size of Tensor object at 0x0000020A1FA3E850>\n"
     ]
    }
   ],
   "source": [
    "t19 = torch.empty(5, 1, 4, 1)\n",
    "t20 = torch.empty(3, 1, 1)\n",
    "print((t19 + t20).size)\n",
    "\n",
    "t21 = torch.empty(1)\n",
    "t22 = torch.empty(3, 1, 7)\n",
    "print((t21 + t22).size)\n",
    "\n",
    "#브로드캐스팅 규칙 위배\n",
    "# 1. 두 텐서의 크기가 같아야함\n",
    "# 2. 둘 중 하나는 차원의 크기가 1이어야함\n",
    "# 밑에 수식은 규칙 2 위배\n",
    "# t25 = torch.empty(5, 2, 4, 1)\n",
    "# t26 = torch.empty(3, 1, 1)\n",
    "# print((t25 + t26).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93e13937714b1910",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T13:57:48.493584Z",
     "start_time": "2025-09-21T13:57:48.448826Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 5., 5., 5.])\n",
      "tensor([25., 25., 25., 25.])\n",
      "tensor([  1.,   4.,  27., 256.])\n"
     ]
    }
   ],
   "source": [
    "t27 = torch.ones(4) * 5\n",
    "print(t27)\n",
    "\n",
    "# torch.pow(input, exponent)\n",
    "# input 텐서의 각 요소를 exponent만큼 거듭제곱\n",
    "t28 = torch.pow(t27, 2)\n",
    "print(t28)\n",
    "\n",
    "exp = torch.arange(1., 5.)\n",
    "a = torch.arange(1., 5.)\n",
    "t29 = torch.pow(a, exp)\n",
    "print(t29)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94db165e3ae8bc98",
   "metadata": {},
   "source": [
    "j_tensor_indexing_slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a6d6c3a242a3514",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T14:01:10.652917Z",
     "start_time": "2025-09-21T14:01:10.618474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 6, 7, 8, 9])\n",
      "tensor([ 1,  6, 11])\n",
      "tensor(7)\n",
      "tensor([ 4,  9, 14])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(\n",
    "    [[0, 1, 2, 3, 4],\n",
    "     [5, 6, 7, 8, 9],\n",
    "     [10, 11, 12, 13, 14]]\n",
    ")\n",
    "\n",
    "print(x[1])\n",
    "print(x[:, 1])\n",
    "print(x[1, 2])\n",
    "print(x[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d62cad3bbcf76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T14:02:13.313537Z",
     "start_time": "2025-09-21T14:02:13.272361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.zeros((6, 6))\n",
    "y[1:4, 2] = 1\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3343ccf5bd65a45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T14:04:26.632397Z",
     "start_time": "2025-09-21T14:04:26.623012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4],\n",
      "        [2, 3, 4, 5]])\n",
      "tensor([[3, 4],\n",
      "        [6, 7]])\n",
      "tensor([[2, 3, 4],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([[1, 2, 3, 4],\n",
      "        [2, 0, 0, 5],\n",
      "        [5, 0, 0, 8]])\n"
     ]
    }
   ],
   "source": [
    "z = torch.tensor(\n",
    "    [[1, 2, 3, 4],\n",
    "     [2, 3, 4, 5],\n",
    "     [5, 6, 7, 8]]\n",
    ")\n",
    "print(z[:2])\n",
    "print(z[1:, 1:3])\n",
    "print(z[:, 1:])\n",
    "\n",
    "z[1:, 1:3] = 0\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c562ea0390528a6",
   "metadata": {},
   "source": [
    "k_tensor_reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b37fda94dba977e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T14:31:28.710188Z",
     "start_time": "2025-09-21T14:31:28.682216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "tensor([[1, 2, 3, 4, 5, 6]])\n",
      "tensor([[0, 1, 2, 3],\n",
      "        [4, 5, 6, 7]])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "# .view(a, b) : [a, b]형태로 reshapeing\n",
    "# .reshape(a, b) : [a, b]형태로 reshapeing\n",
    "\n",
    "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "t2 = t1.view(3, 2)\n",
    "t3 = t1.reshape(1, 6)\n",
    "print(t2)\n",
    "print(t3)\n",
    "\n",
    "t4 = torch.arange(8).view(2, 4)\n",
    "t5 = torch.arange(6).view(2, 3)\n",
    "print(t4)\n",
    "print(t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b936efa6f92a649b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T14:34:51.957918Z",
     "start_time": "2025-09-21T14:34:51.932374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n"
     ]
    }
   ],
   "source": [
    "#squeeze() : 크기가 1인 모든 차원을 제거\n",
    "#squeeze(n) : n번째 차원이 1인 경우 제거\n",
    "t6 = torch.tensor([[[1], [2], [3]]]) #torch.size(1, 1, 3, 1)\n",
    "t7 = t6.squeeze()\n",
    "t8 = t6.squeeze(0)\n",
    "print(t7)\n",
    "print(t8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "738dccfdd3494ac0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T14:44:14.582317Z",
     "start_time": "2025-09-21T14:44:14.573709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([[[1, 2, 3]],\n",
      "\n",
      "        [[4, 5, 6]]]) torch.Size([2, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "t9 = torch.tensor([1, 2, 3])\n",
    "\n",
    "#unsqueeze(n) :input 텐서의 특정위치에 텐서에 크기가 1인 새로운 차원을 추가\n",
    "t10 = t9.unsqueeze(1)\n",
    "print(t10)\n",
    "\n",
    "t11 = torch.tensor(     #tensor.size(2, 3)\n",
    "  [[1, 2, 3],\n",
    "   [4, 5, 6]]\n",
    ")\n",
    "t12 = t11.unsqueeze(1)  #tensor.size(2, 1, 3)\n",
    "print(t12, t12.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce411a7f99c93f68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T14:49:12.305715Z",
     "start_time": "2025-09-21T14:49:12.297802Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6])\n",
      "tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "tensor([[1, 2, 3, 4],\n",
      "        [5, 6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# flatten(): 다차원의 텐서를 1차원 텐서로 펼치는 함수\n",
    "# torch.flatten(input, start_dim=0, end_dim=-1)는 지정된 start_dim부터 end_dim까지의 차원을 1차원으로 병합합니다\n",
    "t13 = torch.tensor([[1, 2, 3],[4, 5, 6]])\n",
    "t14 = t13.flatten()\n",
    "print(t14)\n",
    "\n",
    "t15 = torch.tensor([[[1, 2],    #tensor.size(2, 2, 2)\n",
    "                     [3, 4]],\n",
    "                    [[5, 6],\n",
    "                     [7, 8]]])\n",
    "t16 = torch.flatten(t15)\n",
    "\n",
    "t17 = torch.flatten(t15, start_dim=1) #tensor.size(2, 1, 1)\n",
    "print(t16)\n",
    "print(t17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "17f2cd44f45c21be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T14:53:15.648220Z",
     "start_time": "2025-09-21T14:53:15.609159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5])\n",
      "torch.Size([5, 2, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "# torch.permute(input, dims=(a, b)) : dims=(a, b) 순서로 차원 재배열\n",
    "t18 = torch.randn(2, 3, 5)\n",
    "print(t18.shape)  # torch.Size([2, 3, 5])\n",
    "print(torch.permute(t18, (2, 0, 1)).size())\n",
    "\n",
    "t19 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "t20 = torch.permute(t19, dims=(0, 1))\n",
    "t21 = torch.permute(t19, dims=(1, 0))\n",
    "print(t20)\n",
    "print(t21)\n",
    "\n",
    "# torch.transpose(input, dim0, dim1) : input의 두 차원(dim0, dim1)을 바꿈 (전치행렬)\n",
    "# torch.t()와 동일\n",
    "t22 = torch.transpose(t19, 0, 1)\n",
    "print(t22)\n",
    "\n",
    "t23 = torch.t(t19)\n",
    "print(t23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344a50212a9d2329",
   "metadata": {},
   "source": [
    "l_tensor_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c0ef44e83a3cd5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T15:06:47.320150Z",
     "start_time": "2025-09-21T15:06:47.311945Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "# torch.cat(tensors, dim=0) : 텐서들의 지정된 차원을 따라 \"연결하는\" 함수\n",
    "# 주의! 나머지 차원들은 동일해야함!!\n",
    "t1 = torch.zeros([2, 1, 3])\n",
    "t2 = torch.zeros([2, 3, 3])\n",
    "t3 = torch.zeros([2, 2, 3])\n",
    "\n",
    "t4 = torch.cat([t1, t2, t3], dim=1)\n",
    "print(t4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7b66aff34ed3052",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T15:13:51.774529Z",
     "start_time": "2025-09-21T15:13:51.767274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "t5 = torch.arange(0, 3)  # tensor([0, 1, 2])\n",
    "t6 = torch.arange(3, 8)  # tensor([3, 4, 5, 6, 7])\n",
    "\n",
    "t7 = torch.cat((t5, t6), dim=0) # 차원 0에 따라 연결 >>> torch.Size([8])\n",
    "print(t7.shape)\n",
    "print(t7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "48ef037eaa11c9fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T15:13:49.013977Z",
     "start_time": "2025-09-21T15:13:49.004620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n",
      "torch.Size([2, 6])\n",
      "tensor([[ 0,  1,  2,  6,  7,  8],\n",
      "        [ 3,  4,  5,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "t8 = torch.arange(0, 6).reshape(2, 3)  # torch.Size([2, 3])\n",
    "t9 = torch.arange(6, 12).reshape(2, 3)  # torch.Size([2, 3])\n",
    "\n",
    "# 2차원 텐서간 병합\n",
    "t10 = torch.cat((t8, t9), dim=0) # torch.Size([4, 3])\n",
    "print(t10.size())\n",
    "print(t10)\n",
    "\n",
    "t11 = torch.cat((t8, t9), dim=1) #torch.Size([2, 6])\n",
    "print(t11.size())\n",
    "print(t11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5d5f61f103c2da2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T15:13:45.341158Z",
     "start_time": "2025-09-21T15:13:45.328644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 3])\n",
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11],\n",
      "        [12, 13, 14],\n",
      "        [15, 16, 17]])\n",
      "torch.Size([2, 9])\n",
      "tensor([[ 0,  1,  2,  6,  7,  8, 12, 13, 14],\n",
      "        [ 3,  4,  5,  9, 10, 11, 15, 16, 17]])\n"
     ]
    }
   ],
   "source": [
    "t12 = torch.arange(0, 6).reshape(2, 3)  # torch.Size([2, 3])\n",
    "t13 = torch.arange(6, 12).reshape(2, 3)  # torch.Size([2, 3])\n",
    "t14 = torch.arange(12, 18).reshape(2, 3)  # torch.Size([2, 3])\n",
    "\n",
    "t15 = torch.cat((t12, t13, t14), dim=0) # torch.Size([6, 3])\n",
    "print(t15.size())\n",
    "print(t15)\n",
    "\n",
    "t16 = torch.cat((t12, t13, t14), dim=1) # torch.Size([2, 9])\n",
    "print(t16.size())\n",
    "print(t16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ed7d82d951c98c08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T15:15:01.769734Z",
     "start_time": "2025-09-21T15:15:01.758419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5]],\n",
      "\n",
      "        [[ 6,  7,  8],\n",
      "         [ 9, 10, 11]]])\n",
      "torch.Size([1, 4, 3])\n",
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5],\n",
      "         [ 6,  7,  8],\n",
      "         [ 9, 10, 11]]])\n",
      "torch.Size([1, 2, 6])\n",
      "tensor([[[ 0,  1,  2,  6,  7,  8],\n",
      "         [ 3,  4,  5,  9, 10, 11]]])\n"
     ]
    }
   ],
   "source": [
    "t17 = torch.arange(0, 6).reshape(1, 2, 3)  # torch.Size([1, 2, 3])\n",
    "t18 = torch.arange(6, 12).reshape(1, 2, 3)  # torch.Size([1, 2, 3])\n",
    "\n",
    "t19 = torch.cat((t17, t18), dim=0) # torch.Size([2, 2, 3])\n",
    "print(t19.size())\n",
    "print(t19)\n",
    "\n",
    "t20 = torch.cat((t17, t18), dim=1) # torch.Size([1, 4, 3])\n",
    "print(t20.size())\n",
    "print(t20)\n",
    "\n",
    "t21 = torch.cat((t17, t18), dim=2) # torch.Size([1, 2, 6])\n",
    "print(t21.size())\n",
    "print(t21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fc5aa3dd9576ba",
   "metadata": {},
   "source": [
    "m_tensor_stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a59c189cfc81a02f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T15:34:35.196394Z",
     "start_time": "2025-09-21T15:34:35.183984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 11, 12]]])\n",
      "torch.Size([2, 2, 3]) True\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 7,  8,  9]],\n",
      "\n",
      "        [[ 4,  5,  6],\n",
      "         [10, 11, 12]]])\n",
      "torch.Size([2, 2, 3]) True\n",
      "tensor([[[ 1,  7],\n",
      "         [ 2,  8],\n",
      "         [ 3,  9]],\n",
      "\n",
      "        [[ 4, 10],\n",
      "         [ 5, 11],\n",
      "         [ 6, 12]]])\n",
      "torch.Size([2, 3, 2]) True\n"
     ]
    }
   ],
   "source": [
    "# torch.stack() : 여러 텐서를 쌓아서 새로운 차원을 추가하는 방식으로 결합\n",
    "# 새로운 차원의 숫자는 텐서의 갯수\n",
    "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "t2 = torch.tensor([[7, 8, 9], [10, 11, 12]])\n",
    "\n",
    "t3 = torch.stack([t1, t2], dim=0) # 차원 0번째에 크기가 2인 차원 추가, 깊이 방향으로 쌓는 모양\n",
    "t4 = torch.cat([t1.unsqueeze(dim=0), t2.unsqueeze(dim=0)], dim=0)\n",
    "print(t3)\n",
    "print(t3.shape, t3.equal(t4))\n",
    "\n",
    "t5 = torch.stack([t1, t2], dim=1) # dim=1 >> 각 행을 옆으로 쌓는 모양\n",
    "t6 = torch.cat([t1.unsqueeze(dim=1), t2.unsqueeze(dim=1)], dim=1)\n",
    "print(t5)\n",
    "print(t5.shape, t5.equal(t6))\n",
    "\n",
    "t7 = torch.stack([t1, t2], dim=2)\n",
    "t8 = torch.cat([t1.unsqueeze(dim=2), t2.unsqueeze(dim=2)], dim=2)\n",
    "print(t7)\n",
    "print(t7.shape, t7.equal(t8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "94b9d5b71a5c49ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T15:37:27.768574Z",
     "start_time": "2025-09-21T15:37:27.760595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3]) torch.Size([3])\n",
      "torch.Size([2, 3])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "True\n",
      "torch.Size([3, 2])\n",
      "tensor([[0, 3],\n",
      "        [1, 4],\n",
      "        [2, 5]])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "t9 = torch.arange(0, 3)  # tensor([0, 1, 2])\n",
    "t10 = torch.arange(3, 6)  # tensor([3, 4, 5])\n",
    "\n",
    "print(t9.size(), t10.size()) # torch.Size([3]) torch.Size([3])\n",
    "\n",
    "t11 = torch.stack((t9, t10), dim=0) # torch.Size([2,3])\n",
    "print(t11.size())\n",
    "print(t11)\n",
    "\n",
    "t12 = torch.cat((t9.unsqueeze(0), t10.unsqueeze(0)), dim=0)\n",
    "print(t11.equal(t12))\n",
    "\n",
    "t13 = torch.stack((t9, t10), dim=1) # # >>> torch.Size([3,2])\n",
    "print(t13.size())\n",
    "print(t13)\n",
    "\n",
    "t14 = torch.cat((t9.unsqueeze(1), t10.unsqueeze(1)), dim=1)\n",
    "print(t13.equal(t14))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e841c6a34b117c",
   "metadata": {},
   "source": [
    "n_tensor_vstack_hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dfb802a7068e9155",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T16:30:39.586338Z",
     "start_time": "2025-09-21T16:30:39.576557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "torch.Size([2, 3])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6]])\n",
      "torch.Size([6, 1])\n",
      "torch.Size([2, 2, 3])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 11, 12]],\n",
      "\n",
      "        [[13, 14, 15],\n",
      "         [16, 17, 18]],\n",
      "\n",
      "        [[19, 20, 21],\n",
      "         [22, 23, 24]]])\n",
      "torch.Size([4, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# torch.vstack : 텐서들을 \"수직(vertical)\"으로, 즉 행(row)을 따라 결합\n",
    "# torch.cat(..., dim=0)과 동일한 기능\n",
    "t1 = torch.tensor([1, 2, 3])\n",
    "t2 = torch.tensor([4, 5, 6])\n",
    "t3 = torch.vstack((t1, t2))\n",
    "print(t3)\n",
    "print(t3.shape)\n",
    "\n",
    "t4 = torch.tensor([[1], [2], [3]])\n",
    "t5 = torch.tensor([[4], [5], [6]])\n",
    "t6 = torch.vstack((t4, t5))\n",
    "print(t6)\n",
    "print(t6.shape)\n",
    "\n",
    "t7 = torch.tensor([\n",
    "  [[1, 2, 3], [4, 5, 6]],\n",
    "  [[7, 8, 9], [10, 11, 12]]\n",
    "])\n",
    "print(t7.shape)\n",
    "\n",
    "t8 = torch.tensor([\n",
    "  [[13, 14, 15], [16, 17, 18]],\n",
    "  [[19, 20, 21], [22, 23, 24]]\n",
    "])\n",
    "print(t8.shape)\n",
    "\n",
    "t9 = torch.vstack([t7, t8])\n",
    "print(t9)\n",
    "print(t9.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "27a26a86-d39c-4ba5-94a6-a97ce9c08cb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T16:36:54.332479Z",
     "start_time": "2025-09-21T16:36:54.303698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6])\n",
      "torch.Size([6])\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "torch.Size([3, 2])\n",
      "torch.Size([2, 2, 3])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6],\n",
      "         [13, 14, 15],\n",
      "         [16, 17, 18]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 11, 12],\n",
      "         [19, 20, 21],\n",
      "         [22, 23, 24]]])\n",
      "torch.Size([2, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "# torch.hstack : 텐서들을 \"수평(horizontal)\"으로, 즉 열(column)을 따라 결합\n",
    "# torch.cat(..., dim=1)과 동일한 기능\n",
    "t10 = torch.tensor([1, 2, 3])\n",
    "t11 = torch.tensor([4, 5, 6])\n",
    "t12 = torch.hstack((t10, t11))\n",
    "print(t12)\n",
    "print(t12.shape)\n",
    "\n",
    "t13 = torch.tensor([[1], [2], [3]])\n",
    "t14 = torch.tensor([[4], [5], [6]])\n",
    "t15 = torch.hstack((t13, t14))\n",
    "print(t15)\n",
    "print(t15.shape)\n",
    "\n",
    "t16 = torch.tensor([\n",
    "  [[1, 2, 3], [4, 5, 6]],\n",
    "  [[7, 8, 9], [10, 11, 12]]\n",
    "])\n",
    "print(t16.shape)\n",
    "\n",
    "t17 = torch.tensor([\n",
    "  [[13, 14, 15], [16, 17, 18]],\n",
    "  [[19, 20, 21], [22, 23, 24]]\n",
    "])\n",
    "print(t17.shape)\n",
    "\n",
    "t18 = torch.hstack([t16, t17])\n",
    "print(t18)\n",
    "print(t18.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b9c102-cf88-48b7-b623-6b25032c7a66",
   "metadata": {},
   "source": [
    "숙제 후기\n",
    "\n",
    "처음에는 파이썬과 비슷한 부분이 많아서 굳이 해야하나 생각했지만\n",
    "차원에 관하여 코드를 작성하며 공부하면서 제 생각과 다른 구조가 나오는 경우가 많아지면서 뒷 부분에는 많은 시간을 할애한 것 같습니다.\n",
    "예전 기초데이터과학이라는 과목을 수강할 때 데이터 전처리에 대해 공부하였는데 이걸 먼저 알고 수강하였다면 큰 도움이 될 것 같다는 생각을 하게 되었습니다.\n",
    "데이터 전처리를 할 때 이번 과제를 하면서 공부한 것이 큰 도움이 될 것 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9b1112-70d4-471b-be7a-c128af0629e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
